{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN \n",
    "\n",
    "In this notebook we consider a simple example of an RNN and used a quite artifical data generating process (if you have a better idea / story please contact me). \n",
    "\n",
    "The example has been motivated by:\n",
    "http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html. \n",
    "\n",
    "Other Resources for RNNs:\n",
    "\n",
    "* http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\n",
    "* http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html\n",
    "* http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "* http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* http://www.deeplearningbook.org/contents/rnn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.0',\n",
       " sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from six.moves.cPickle import loads\n",
    "import numpy as np\n",
    "import sys\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "keras = tensorflow.keras\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__, sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config variables (see below)\n",
    "num_steps = 40     # number of truncated backprop steps\n",
    "batch_size = 200  # number of minibatches b\n",
    "num_classes_in = 3   # number of classes in the input\n",
    "num_classes_out = 2   # number of classes in the output\n",
    "state_size = 4    # number of classes in the state\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Helper functions\n",
    "def one_hot(Y, max):\n",
    "    d = np.zeros((len(Y),max), dtype='int32')\n",
    "    for row,col in enumerate(Y):\n",
    "        d[row, col] = 1\n",
    "    return d    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the task\n",
    "\n",
    "We consider a network which predicts at each point in time a variable $\\hat{y}_t$ based on earlier values of $\\hat{y}_{t'}$ covariates $x_t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example data  (I screama, you screama, we all screama for I screama)\n",
    "\n",
    "We need some data to play around with RNNs. They are capable of doing quite complicated things such as language models and so on. For this example, we want to generate the data ourself. We have to come up with a process which creates $x_t$ which itself can be influcenced by events $x_{t'}$ which happend before $t$. Further, we have to come up with $y_t$ which depends on $x_t'$ for timepoints $t' \\le t$. \n",
    "\n",
    "To keep it simple, we analyse the following quite artifical process in which the weather $x_{t'}$ for $t' \\le t$ influences our stock on icecream $y_t$. We then see if the RNN is capable of reconstructing that process.\n",
    "\n",
    "#### Definition of the simple process\n",
    "The weather $x_t$ at a certain point in time $t$ has three states (sunny, rainy, cloudy), which we model as $x_t = (1,0,0)$, $x_t = (0,1,0)$, and $x_t = (0,0,1)$ repectively. We assume that the weather is completly random (of course we could model more complex scenarios). \n",
    "\n",
    "We have an icecream store capable of holding 2 units of icecream and we start with a full store. When it is sunny we sell one unit of icecream. We have the strange policy that we order  on unit of icecream when it's cloudy. It takes 3 days to deliever the ice cream, we accept the ice cream if we do not have a full stock.\n",
    "\n",
    "This enables us to model $y_t$ the state of the store $(1,0)$ for out of stock and $(0,1)$ for in stock. We create the one-hot-encoded data in the graph later. For now we use integers but keep in mind that the data is categorical. \n",
    "\n",
    "** The important part is that, we have values $y_t$ which can be prediced from earlier** $x_t$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    Xs = np.array(np.random.choice(3, size=(size,))) #Random Weather\n",
    "    Y = []\n",
    "    ice = 2 #Our stock of icecream at start\n",
    "    for t,x in enumerate(Xs):\n",
    "        # (t-3) >= 0 the first ice cream could be delivered on day 3\n",
    "        # Xs[t - 3] claudy three days before today => we ordered ice cream\n",
    "        # ice < 2 not full\n",
    "        if (t - 3) >= 0 and Xs[t - 3] == 1 and ice < 2: \n",
    "            ice += 1\n",
    "        if x == 0: # It is sunny we therefore sell ice, if we have\n",
    "            if ice > 0: # We have ice cream\n",
    "                ice -= 1\n",
    "        if ice > 0: #We are not out of stock\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "    return Xs, np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0,\n",
       "        0, 2, 1, 0, 1, 1]),\n",
       " array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = gen_data(50000) #Global variables holding the input and output\n",
    "(X_train[0:50], Y_train[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass in numpy\n",
    "To better illustrate the used method, we first do a forward-pass of the RNN using numpy. We load the weights which we calculated previously with the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_, b_, V_, bv_ = np.load('rnn_weights_tf1.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture of the network \n",
    "We now define the network, we do not consider the output nodes yet.\n",
    "A single RNN cell is shown in the figure below in the middle:\n",
    "\n",
    "![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)\n",
    "Image taken from: [Colah's RNN Blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "The joining of the two lines coming from the previous state $h_{t-1}$ and the current x-values $x_t$ is a concantination to a vector  $[h_{t-1}, x_{t}]$ of size `state_size + num_classes_in`. Alternatively, instead of concatinating, one could also use two matrices $W_x$ and $W_h$ and keep the states seperate. This is mathematically completely identical. The new state $h_t$ is then calculated as:\n",
    "\n",
    "$$\n",
    "    h_{t} = \\tanh([h_{t-1}, x_{t}] \\cdot W + b) = \\tanh(h_{t-1} \\cdot W_h + x_{t} \\cdot U + b)\n",
    "$$\n",
    "\n",
    "The dynamic of the hidden state $h_{t}$ is determined by $W$ (and $b$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 4)\n",
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.19089293,  1.2079829 ,  0.00908419, -0.9110236 ],\n",
       "        [-1.0788563 , -0.34288317,  0.7271212 ,  1.4178839 ],\n",
       "        [-0.20597383, -0.19254826,  0.7025221 , -0.54543966],\n",
       "        [ 1.0341463 ,  0.67596245, -0.93610775,  0.37894768],\n",
       "        [-0.16711316,  1.0264009 , -0.89726377, -0.42267284],\n",
       "        [ 0.20204762, -1.2146151 ,  0.02345279,  0.41776735],\n",
       "        [-1.4482121 ,  0.28976035, -1.8760067 , -1.1563133 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.1347418 ,  0.28151226,  0.17300364, -0.321079  ], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Internal states\n",
    "print(W_.shape)\n",
    "print(b_.shape)\n",
    "W_, b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.18110763,  0.14144787],\n",
       "        [ 2.2433083 , -3.244251  ],\n",
       "        [-0.05769794,  0.35383844],\n",
       "        [ 0.0802527 , -0.5142712 ]], dtype=float32),\n",
       " array([-0.35922614,  0.35923496], dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Connecting to the outpur\n",
    "print(V_.shape)\n",
    "print(bv_.shape)\n",
    "V_, bv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.] ---> [-0.0711118   0.08873004  0.70417075 -0.69960102]\n"
     ]
    }
   ],
   "source": [
    "# The first state\n",
    "h0 = np.zeros(state_size) #We start with 0 initial state\n",
    "x1 = one_hot(X_train, num_classes_in)[0] #Make a vector\n",
    "h1 = np.tanh(np.matmul(np.concatenate([x1, h0]), W_) + b_)\n",
    "print(h0, \"--->\", h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could repeat those transitions of the hidden states to get a sequence of hidden states:\n",
    "\n",
    "$h_0 \\rightarrow h_1 \\rightarrow h_2 \\rightarrow h_3 \\rightarrow h_4 \\ldots $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_forward(state, X_train):\n",
    "    hs = []\n",
    "    for t in range(len(X_train)):\n",
    "        # Note that TF concatenates [Input, State]\n",
    "        state = np.tanh(np.matmul(np.concatenate([X_train[t,:],state]), W_) + b_)\n",
    "        hs.append(state)\n",
    "    return hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.0711118 ,  0.08873004,  0.70417075, -0.69960102]),\n",
       " array([ 0.76614542,  0.4418166 ,  0.90478852, -0.19104017]),\n",
       " array([ 0.80289923, -0.09371934,  0.14058029, -0.16258438]),\n",
       " array([ 0.77733682,  0.30737024,  0.47485703, -0.26912559]),\n",
       " array([ 0.82809942,  0.93229872, -0.29620752, -0.50640012])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_forward(h0, one_hot(X_train[0:5],num_classes_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add some output. For each time step the output is produced by multiplying the hidden state with:\n",
    "\n",
    "$o_t = h_t \\cdot V + b_{\\tt{v}}$\n",
    "\n",
    "This is a logit, the final the probability of output class is the softmax of the logit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.24407249,  0.67026118]), array([0.28611385, 0.71388615]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<---- your code here (calculate the output state o1 for timestep 1 from h1, V_ and the bias bv_) ---->\n",
    "o1 = np.matmul(h1, V_) + bv_\n",
    "#<---- your code here (calculate probability from the state o1) using softmax ---->\n",
    "prob_1 = np.exp(o1)/np.sum(np.exp(o1))\n",
    "#<---- end your code here  ---->\n",
    "o1, prob_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = rnn_forward(h0, one_hot(X_train,3))\n",
    "pt = []\n",
    "for t in range(len(h)):\n",
    "    ot = np.matmul(h[t], V_) + bv_\n",
    "    pt.append(np.exp(ot)/np.sum(np.exp(ot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0.28611385, 0.71388615]),\n",
       "  array([0.72571267, 0.27428733]),\n",
       "  array([0.16161706, 0.83838294]),\n",
       "  array([0.58954736, 0.41045264]),\n",
       "  array([0.98113328, 0.01886672]),\n",
       "  array([0.98589376, 0.01410624]),\n",
       "  array([0.9805026, 0.0194974]),\n",
       "  array([0.97813046, 0.02186954]),\n",
       "  array([0.98805885, 0.01194115]),\n",
       "  array([0.96179709, 0.03820291])],\n",
       " array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0]),\n",
       " array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt[0:10], np.argmax(pt[0:30],axis=1), Y_train[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98318"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.argmax(pt, axis=1) == Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_loss = 0\n",
    "for i in range(len(Y_train)):\n",
    "    tot_loss += -np.log(pt[i][Y_train[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06928991983381633"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_loss / len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the network\n",
    "## Preparation of the Minibatch\n",
    "\n",
    "In this example, we have in principle a large stream of data $x$ and $y$. For efficiency reason we split the stream in minibatches of a certain length. For this task we could also imagin to have several realizations of that icecream process, so that it would also be natural to split the process into mini batches. \n",
    "\n",
    "For simplicity, we create the minibatch by randomly cutting out `batch_size` entries of fixed length `num_steps`. Other, more advanced ways of doing so are possible. See e.g. https://danijar.com/variable-sequence-lengths-in-tensorflow/. For the time being, we thus consider the input tensor $X_{btc}$ for the minibatch to be of the following form:\n",
    "\n",
    "* $b$ having `batch_size` entries\n",
    "* $t$ loops over the unrolled timestamps (`num_steps`)\n",
    "* $c$ has the dimension of the one-hot-coded input classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_matrix(Xs, Ys, size = 32, num_steps = 50):\n",
    "    data_x = np.zeros([size, num_steps, 3], dtype=np.int32)\n",
    "    data_y = np.zeros([size, num_steps, 2], dtype=np.int32)\n",
    "    for i in range(1,size):\n",
    "        s = int(np.random.uniform(0, len(Xs) - num_steps))\n",
    "        data_x[i] = one_hot(Xs[s : s + num_steps],3)\n",
    "        data_y[i] = one_hot(Ys[s : s + num_steps],2)\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 40, 3), (10000, 40, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = data_matrix(X_train, Y_train, size=10000, num_steps=num_steps)\n",
    "X.shape, Y.shape\n",
    "#print (X[0:2,0:5])\n",
    "#print (Y[0:2,0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model with keras\n",
    "\n",
    "**Keras assumes (batch, time, input_dimension)** as input tensor. The batch dimension needs not to be specified (side note that specifying it to `None` would not work).\n",
    "\n",
    "\n",
    "In our model we calculate the loss using all hidden timepoints. This is many-to-many situation is different for example to a sentiment classifier, where we we have a many-to-one situation. \n",
    "\n",
    "Not just the latest one (in time). Hence we set `return_sequences=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "RNN (SimpleRNN)              (None, 40, 4)             32        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40, 2)             10        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "rnn = keras.layers.SimpleRNN(state_size, input_shape=(num_steps, 3), return_sequences=True, name='RNN')\n",
    "model.add(rnn) \n",
    "#model.input_shape --> (None, 40, 3)\n",
    "#model.output_shape --> (None, 40, 4) \n",
    "\n",
    "# <-- Your code here \n",
    "# Add an output layer connecting with the hidden state of the RNN\n",
    "model.add(keras.layers.Dense(2))\n",
    "# <-- End code here \n",
    "\n",
    "#model.output_shape --> (None, 40, 2) \n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the RNN we have: \n",
    "\n",
    "Internal: (4+3)*4 + 4 = 32\n",
    "\n",
    "Output: 4*2+2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "9500/9500 - 3s - loss: 2.5917 - accuracy: 0.5230 - val_loss: 1.1079 - val_accuracy: 0.5245\n",
      "Epoch 2/100\n",
      "9500/9500 - 2s - loss: 0.7833 - accuracy: 0.5847 - val_loss: 0.6841 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "9500/9500 - 2s - loss: 0.6006 - accuracy: 0.7085 - val_loss: 0.5381 - val_accuracy: 0.7566\n",
      "Epoch 4/100\n",
      "9500/9500 - 2s - loss: 0.4676 - accuracy: 0.7864 - val_loss: 0.4283 - val_accuracy: 0.8049\n",
      "Epoch 5/100\n",
      "9500/9500 - 2s - loss: 0.4025 - accuracy: 0.8171 - val_loss: 0.3822 - val_accuracy: 0.8282\n",
      "Epoch 6/100\n",
      "9500/9500 - 2s - loss: 0.3594 - accuracy: 0.8405 - val_loss: 0.3417 - val_accuracy: 0.8519\n",
      "Epoch 7/100\n",
      "9500/9500 - 2s - loss: 0.3025 - accuracy: 0.8724 - val_loss: 0.2947 - val_accuracy: 0.8859\n",
      "Epoch 8/100\n",
      "9500/9500 - 2s - loss: 0.2623 - accuracy: 0.9058 - val_loss: 0.2679 - val_accuracy: 0.9075\n",
      "Epoch 9/100\n",
      "9500/9500 - 2s - loss: 0.2513 - accuracy: 0.9148 - val_loss: 0.2729 - val_accuracy: 0.9104\n",
      "Epoch 10/100\n",
      "9500/9500 - 2s - loss: 0.2548 - accuracy: 0.9199 - val_loss: 0.2711 - val_accuracy: 0.9119\n",
      "Epoch 11/100\n",
      "9500/9500 - 2s - loss: 0.2513 - accuracy: 0.9233 - val_loss: 0.2646 - val_accuracy: 0.9210\n",
      "Epoch 12/100\n",
      "9500/9500 - 2s - loss: 0.2425 - accuracy: 0.9255 - val_loss: 0.2539 - val_accuracy: 0.9222\n",
      "Epoch 13/100\n",
      "9500/9500 - 2s - loss: 0.2335 - accuracy: 0.9288 - val_loss: 0.2466 - val_accuracy: 0.9265\n",
      "Epoch 14/100\n",
      "9500/9500 - 2s - loss: 0.2276 - accuracy: 0.9317 - val_loss: 0.2411 - val_accuracy: 0.9280\n",
      "Epoch 15/100\n",
      "9500/9500 - 2s - loss: 0.2240 - accuracy: 0.9351 - val_loss: 0.2400 - val_accuracy: 0.9352\n",
      "Epoch 16/100\n",
      "9500/9500 - 2s - loss: 0.2208 - accuracy: 0.9388 - val_loss: 0.2361 - val_accuracy: 0.9390\n",
      "Epoch 17/100\n",
      "9500/9500 - 2s - loss: 0.2176 - accuracy: 0.9415 - val_loss: 0.2341 - val_accuracy: 0.9360\n",
      "Epoch 18/100\n",
      "9500/9500 - 2s - loss: 0.2155 - accuracy: 0.9427 - val_loss: 0.2295 - val_accuracy: 0.9424\n",
      "Epoch 19/100\n",
      "9500/9500 - 2s - loss: 0.2126 - accuracy: 0.9442 - val_loss: 0.2275 - val_accuracy: 0.9435\n",
      "Epoch 20/100\n",
      "9500/9500 - 2s - loss: 0.2110 - accuracy: 0.9449 - val_loss: 0.2237 - val_accuracy: 0.9426\n",
      "Epoch 21/100\n",
      "9500/9500 - 2s - loss: 0.2086 - accuracy: 0.9460 - val_loss: 0.2216 - val_accuracy: 0.9460\n",
      "Epoch 22/100\n",
      "9500/9500 - 2s - loss: 0.2068 - accuracy: 0.9469 - val_loss: 0.2279 - val_accuracy: 0.9374\n",
      "Epoch 23/100\n",
      "9500/9500 - 2s - loss: 0.2049 - accuracy: 0.9473 - val_loss: 0.2184 - val_accuracy: 0.9477\n",
      "Epoch 24/100\n",
      "9500/9500 - 2s - loss: 0.2039 - accuracy: 0.9480 - val_loss: 0.2207 - val_accuracy: 0.9428\n",
      "Epoch 25/100\n",
      "9500/9500 - 2s - loss: 0.2026 - accuracy: 0.9478 - val_loss: 0.2161 - val_accuracy: 0.9456\n",
      "Epoch 26/100\n",
      "9500/9500 - 2s - loss: 0.2023 - accuracy: 0.9470 - val_loss: 0.2156 - val_accuracy: 0.9472\n",
      "Epoch 27/100\n",
      "9500/9500 - 2s - loss: 0.2011 - accuracy: 0.9472 - val_loss: 0.2125 - val_accuracy: 0.9488\n",
      "Epoch 28/100\n",
      "9500/9500 - 2s - loss: 0.1999 - accuracy: 0.9481 - val_loss: 0.2149 - val_accuracy: 0.9462\n",
      "Epoch 29/100\n",
      "9500/9500 - 2s - loss: 0.1994 - accuracy: 0.9482 - val_loss: 0.2124 - val_accuracy: 0.9477\n",
      "Epoch 30/100\n",
      "9500/9500 - 2s - loss: 0.1995 - accuracy: 0.9485 - val_loss: 0.2114 - val_accuracy: 0.9485\n",
      "Epoch 31/100\n",
      "9500/9500 - 2s - loss: 0.1987 - accuracy: 0.9484 - val_loss: 0.2130 - val_accuracy: 0.9459\n",
      "Epoch 32/100\n",
      "9500/9500 - 2s - loss: 0.1984 - accuracy: 0.9488 - val_loss: 0.2084 - val_accuracy: 0.9485\n",
      "Epoch 33/100\n",
      "9500/9500 - 2s - loss: 0.1966 - accuracy: 0.9492 - val_loss: 0.2088 - val_accuracy: 0.9485\n",
      "Epoch 34/100\n",
      "9500/9500 - 2s - loss: 0.1968 - accuracy: 0.9494 - val_loss: 0.2063 - val_accuracy: 0.9485\n",
      "Epoch 35/100\n",
      "9500/9500 - 2s - loss: 0.1953 - accuracy: 0.9496 - val_loss: 0.2067 - val_accuracy: 0.9503\n",
      "Epoch 36/100\n",
      "9500/9500 - 2s - loss: 0.1953 - accuracy: 0.9493 - val_loss: 0.2049 - val_accuracy: 0.9500\n",
      "Epoch 37/100\n",
      "9500/9500 - 2s - loss: 0.1940 - accuracy: 0.9501 - val_loss: 0.2054 - val_accuracy: 0.9488\n",
      "Epoch 38/100\n",
      "9500/9500 - 2s - loss: 0.1946 - accuracy: 0.9500 - val_loss: 0.2058 - val_accuracy: 0.9477\n",
      "Epoch 39/100\n",
      "9500/9500 - 2s - loss: 0.1942 - accuracy: 0.9498 - val_loss: 0.2079 - val_accuracy: 0.9480\n",
      "Epoch 40/100\n",
      "9500/9500 - 2s - loss: 0.1982 - accuracy: 0.9475 - val_loss: 0.2102 - val_accuracy: 0.9465\n",
      "Epoch 41/100\n",
      "9500/9500 - 2s - loss: 0.1935 - accuracy: 0.9501 - val_loss: 0.2062 - val_accuracy: 0.9469\n",
      "Epoch 42/100\n",
      "9500/9500 - 2s - loss: 0.1963 - accuracy: 0.9491 - val_loss: 0.2058 - val_accuracy: 0.9481\n",
      "Epoch 43/100\n",
      "9500/9500 - 2s - loss: 0.1938 - accuracy: 0.9503 - val_loss: 0.2036 - val_accuracy: 0.9487\n",
      "Epoch 44/100\n",
      "9500/9500 - 2s - loss: 0.1935 - accuracy: 0.9500 - val_loss: 0.2124 - val_accuracy: 0.9445\n",
      "Epoch 45/100\n",
      "9500/9500 - 2s - loss: 0.1934 - accuracy: 0.9500 - val_loss: 0.2027 - val_accuracy: 0.9490\n",
      "Epoch 46/100\n",
      "9500/9500 - 2s - loss: 0.1922 - accuracy: 0.9500 - val_loss: 0.2057 - val_accuracy: 0.9477\n",
      "Epoch 47/100\n",
      "9500/9500 - 2s - loss: 0.1924 - accuracy: 0.9500 - val_loss: 0.2023 - val_accuracy: 0.9491\n",
      "Epoch 48/100\n",
      "9500/9500 - 2s - loss: 0.1914 - accuracy: 0.9503 - val_loss: 0.2045 - val_accuracy: 0.9478\n",
      "Epoch 49/100\n",
      "9500/9500 - 2s - loss: 0.1926 - accuracy: 0.9502 - val_loss: 0.2022 - val_accuracy: 0.9482\n",
      "Epoch 50/100\n",
      "9500/9500 - 2s - loss: 0.1915 - accuracy: 0.9504 - val_loss: 0.2147 - val_accuracy: 0.9423\n",
      "Epoch 51/100\n",
      "9500/9500 - 2s - loss: 0.1911 - accuracy: 0.9506 - val_loss: 0.2025 - val_accuracy: 0.9493\n",
      "Epoch 52/100\n",
      "9500/9500 - 2s - loss: 0.1914 - accuracy: 0.9504 - val_loss: 0.2014 - val_accuracy: 0.9492\n",
      "Epoch 53/100\n",
      "9500/9500 - 2s - loss: 0.1913 - accuracy: 0.9503 - val_loss: 0.2025 - val_accuracy: 0.9484\n",
      "Epoch 54/100\n",
      "9500/9500 - 2s - loss: 0.1907 - accuracy: 0.9502 - val_loss: 0.2060 - val_accuracy: 0.9467\n",
      "Epoch 55/100\n",
      "9500/9500 - 2s - loss: 0.1912 - accuracy: 0.9503 - val_loss: 0.2039 - val_accuracy: 0.9481\n",
      "Epoch 56/100\n",
      "9500/9500 - 2s - loss: 0.1909 - accuracy: 0.9505 - val_loss: 0.2017 - val_accuracy: 0.9495\n",
      "Epoch 57/100\n",
      "9500/9500 - 2s - loss: 0.1912 - accuracy: 0.9500 - val_loss: 0.2020 - val_accuracy: 0.9490\n",
      "Epoch 58/100\n",
      "9500/9500 - 2s - loss: 0.1909 - accuracy: 0.9500 - val_loss: 0.2026 - val_accuracy: 0.9477\n",
      "Epoch 59/100\n",
      "9500/9500 - 2s - loss: 0.1907 - accuracy: 0.9500 - val_loss: 0.2013 - val_accuracy: 0.9488\n",
      "Epoch 60/100\n",
      "9500/9500 - 2s - loss: 0.1905 - accuracy: 0.9503 - val_loss: 0.2090 - val_accuracy: 0.9451\n",
      "Epoch 61/100\n",
      "9500/9500 - 2s - loss: 0.1906 - accuracy: 0.9506 - val_loss: 0.2073 - val_accuracy: 0.9454\n",
      "Epoch 62/100\n",
      "9500/9500 - 2s - loss: 0.1901 - accuracy: 0.9504 - val_loss: 0.2089 - val_accuracy: 0.9458\n",
      "Epoch 63/100\n",
      "9500/9500 - 2s - loss: 0.1908 - accuracy: 0.9500 - val_loss: 0.2019 - val_accuracy: 0.9481\n",
      "Epoch 64/100\n",
      "9500/9500 - 2s - loss: 0.1900 - accuracy: 0.9501 - val_loss: 0.2006 - val_accuracy: 0.9481\n",
      "Epoch 65/100\n",
      "9500/9500 - 2s - loss: 0.1899 - accuracy: 0.9500 - val_loss: 0.2012 - val_accuracy: 0.9495\n",
      "Epoch 66/100\n",
      "9500/9500 - 2s - loss: 0.1899 - accuracy: 0.9505 - val_loss: 0.2005 - val_accuracy: 0.9489\n",
      "Epoch 67/100\n",
      "9500/9500 - 2s - loss: 0.1898 - accuracy: 0.9503 - val_loss: 0.2015 - val_accuracy: 0.9482\n",
      "Epoch 68/100\n",
      "9500/9500 - 2s - loss: 0.1894 - accuracy: 0.9503 - val_loss: 0.2002 - val_accuracy: 0.9488\n",
      "Epoch 69/100\n",
      "9500/9500 - 2s - loss: 0.1898 - accuracy: 0.9503 - val_loss: 0.2006 - val_accuracy: 0.9489\n",
      "Epoch 70/100\n",
      "9500/9500 - 2s - loss: 0.1899 - accuracy: 0.9501 - val_loss: 0.1994 - val_accuracy: 0.9485\n",
      "Epoch 71/100\n",
      "9500/9500 - 2s - loss: 0.1895 - accuracy: 0.9501 - val_loss: 0.2048 - val_accuracy: 0.9469\n",
      "Epoch 72/100\n",
      "9500/9500 - 2s - loss: 0.1892 - accuracy: 0.9499 - val_loss: 0.2000 - val_accuracy: 0.9491\n",
      "Epoch 73/100\n",
      "9500/9500 - 2s - loss: 0.1891 - accuracy: 0.9501 - val_loss: 0.2028 - val_accuracy: 0.9470\n",
      "Epoch 74/100\n",
      "9500/9500 - 2s - loss: 0.1889 - accuracy: 0.9503 - val_loss: 0.1999 - val_accuracy: 0.9482\n",
      "Epoch 75/100\n",
      "9500/9500 - 2s - loss: 0.1895 - accuracy: 0.9501 - val_loss: 0.2005 - val_accuracy: 0.9481\n",
      "Epoch 76/100\n",
      "9500/9500 - 2s - loss: 0.1890 - accuracy: 0.9500 - val_loss: 0.2006 - val_accuracy: 0.9482\n",
      "Epoch 77/100\n",
      "9500/9500 - 2s - loss: 0.1888 - accuracy: 0.9498 - val_loss: 0.2021 - val_accuracy: 0.9473\n",
      "Epoch 78/100\n",
      "9500/9500 - 2s - loss: 0.1889 - accuracy: 0.9501 - val_loss: 0.1982 - val_accuracy: 0.9484\n",
      "Epoch 79/100\n",
      "9500/9500 - 2s - loss: 0.1884 - accuracy: 0.9501 - val_loss: 0.1991 - val_accuracy: 0.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "9500/9500 - 2s - loss: 0.1882 - accuracy: 0.9499 - val_loss: 0.2019 - val_accuracy: 0.9474\n",
      "Epoch 81/100\n",
      "9500/9500 - 2s - loss: 0.1885 - accuracy: 0.9498 - val_loss: 0.2007 - val_accuracy: 0.9477\n",
      "Epoch 82/100\n",
      "9500/9500 - 2s - loss: 0.1886 - accuracy: 0.9500 - val_loss: 0.2004 - val_accuracy: 0.9484\n",
      "Epoch 83/100\n",
      "9500/9500 - 2s - loss: 0.1874 - accuracy: 0.9500 - val_loss: 0.2004 - val_accuracy: 0.9475\n",
      "Epoch 84/100\n",
      "9500/9500 - 2s - loss: 0.1889 - accuracy: 0.9494 - val_loss: 0.2035 - val_accuracy: 0.9467\n",
      "Epoch 85/100\n",
      "9500/9500 - 2s - loss: 0.1881 - accuracy: 0.9498 - val_loss: 0.2002 - val_accuracy: 0.9479\n",
      "Epoch 86/100\n",
      "9500/9500 - 2s - loss: 0.1880 - accuracy: 0.9499 - val_loss: 0.2015 - val_accuracy: 0.9463\n",
      "Epoch 87/100\n",
      "9500/9500 - 2s - loss: 0.1876 - accuracy: 0.9497 - val_loss: 0.2000 - val_accuracy: 0.9487\n",
      "Epoch 88/100\n",
      "9500/9500 - 2s - loss: 0.1878 - accuracy: 0.9499 - val_loss: 0.1993 - val_accuracy: 0.9481\n",
      "Epoch 89/100\n",
      "9500/9500 - 2s - loss: 0.1873 - accuracy: 0.9497 - val_loss: 0.1995 - val_accuracy: 0.9478\n",
      "Epoch 90/100\n",
      "9500/9500 - 2s - loss: 0.1869 - accuracy: 0.9498 - val_loss: 0.1975 - val_accuracy: 0.9476\n",
      "Epoch 91/100\n",
      "9500/9500 - 2s - loss: 0.1887 - accuracy: 0.9486 - val_loss: 0.1990 - val_accuracy: 0.9480\n",
      "Epoch 92/100\n",
      "9500/9500 - 2s - loss: 0.1874 - accuracy: 0.9495 - val_loss: 0.2022 - val_accuracy: 0.9452\n",
      "Epoch 93/100\n",
      "9500/9500 - 2s - loss: 0.1874 - accuracy: 0.9494 - val_loss: 0.2043 - val_accuracy: 0.9440\n",
      "Epoch 94/100\n",
      "9500/9500 - 2s - loss: 0.1870 - accuracy: 0.9495 - val_loss: 0.1978 - val_accuracy: 0.9484\n",
      "Epoch 95/100\n",
      "9500/9500 - 2s - loss: 0.1868 - accuracy: 0.9497 - val_loss: 0.2016 - val_accuracy: 0.9457\n",
      "Epoch 96/100\n",
      "9500/9500 - 2s - loss: 0.1867 - accuracy: 0.9496 - val_loss: 0.1981 - val_accuracy: 0.9468\n",
      "Epoch 97/100\n",
      "9500/9500 - 2s - loss: 0.1860 - accuracy: 0.9496 - val_loss: 0.1998 - val_accuracy: 0.9459\n",
      "Epoch 98/100\n",
      "9500/9500 - 2s - loss: 0.1866 - accuracy: 0.9497 - val_loss: 0.1969 - val_accuracy: 0.9482\n",
      "Epoch 99/100\n",
      "9500/9500 - 2s - loss: 0.1867 - accuracy: 0.9496 - val_loss: 0.2001 - val_accuracy: 0.9479\n",
      "Epoch 100/100\n",
      "9500/9500 - 2s - loss: 0.1863 - accuracy: 0.9497 - val_loss: 0.1975 - val_accuracy: 0.9472\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=100, verbose=2, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f74d6606e48>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the development of the accuracy and loss during training\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,(1))\n",
    "plt.plot(history.history['accuracy'],linestyle='-.')\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,(2))\n",
    "plt.plot(history.history['loss'],linestyle='-.')\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1899680873155594, 0.9499875]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the training, since we did use only a random subset of the data\n",
    "X, Y = data_matrix(X_train, Y_train, size=1000, num_steps=num_steps)\n",
    "model.evaluate(X,Y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.21605968, -0.02948334,  0.13601376, -1.2223743 ],\n",
       "        [ 0.10594247,  1.8724391 ,  0.23321001,  0.2734687 ],\n",
       "        [ 0.16046026, -0.04228318,  0.12141945,  0.24082775]],\n",
       "       dtype=float32),\n",
       " array([[ 0.7338864 , -0.0139803 , -0.07297333,  1.531527  ],\n",
       "        [ 0.19304346,  0.0433125 , -1.7489346 ,  0.02920447],\n",
       "        [-2.6149638 ,  0.02548098, -0.17421581, -0.21342318],\n",
       "        [ 0.10220984, -0.00775155, -0.03905404,  1.0599148 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.1745347 , -0.187638  , -0.39152995, -0.49653885], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 40, 4)             108       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 40, 4)             144       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40, 2)             10        \n",
      "=================================================================\n",
      "Total params: 262\n",
      "Trainable params: 262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.GRU(state_size, return_sequences=True, input_shape=(num_steps, 3)))\n",
    "rnn = keras.layers.LSTM(state_size, return_sequences=True) #Need to be true\n",
    "model.add(rnn) \n",
    "\n",
    "#model.input_shape --> (None, 40, 3)\n",
    "#model.output_shape --> (None, 40, 4) \n",
    "\n",
    "\n",
    "model.add(keras.layers.Dense(2))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
